<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Single Instruction Multiple Data (SIMD) | Harlinn</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Single Instruction Multiple Data (SIMD)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This is my personal site." />
<meta property="og:description" content="This is my personal site." />
<link rel="canonical" href="https://harlinn.github.io/Cpp/Cpp/Math/SimdOperations.html" />
<meta property="og:url" content="https://harlinn.github.io/Cpp/Cpp/Math/SimdOperations.html" />
<meta property="og:site_name" content="Harlinn" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Single Instruction Multiple Data (SIMD)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"This is my personal site.","headline":"Single Instruction Multiple Data (SIMD)","url":"https://harlinn.github.io/Cpp/Cpp/Math/SimdOperations.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://harlinn.github.io/feed.xml" title="Harlinn" /><script type="text/javascript" id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="importmap">
        {
            "imports":
            {
            "three": "https://cdn.jsdelivr.net/npm/three@0.171.0/build/three.module.min.js" ,
            "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.171.0/examples/jsm/"
            }
        }
    </script>
</head>
<body><header class="site-header" role="banner">
    <div id="animatedHeader" height="120px" width="100%">
        <script type="x-shader/x-vertex" id="vertexshader">
            attribute float scale;
            void main() {
                vec4 mvPosition = modelViewMatrix * vec4( position, 1.0 );
                gl_PointSize = scale * ( 100.0 / - mvPosition.z );
                gl_Position = projectionMatrix * mvPosition;
            }

        </script>

        <script type="x-shader/x-fragment" id="fragmentshader">
            uniform vec3 color;
            void main() {
                if ( length( gl_PointCoord - vec2( 0.5, 0.5 ) ) > 0.475 )  discard;
                gl_FragColor = vec4( color, 0.8 );
            }
        </script>

        <script type="module">

			import * as THREE from 'three';

			const SEPARATION = 100, AMOUNTX = 50, AMOUNTY = 50;

			let container; 
			let camera, scene, renderer;

			let particles, count = 0;

			let mouseX = 0, mouseY = 0;

			let animatedHeaderHeight = 120;

            let windowHalfX = window.innerWidth / 2;
            let windowHalfY = animatedHeaderHeight/2.0;

			init();

			function init() {

                container = document.querySelector('#animatedHeader');

                camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 1, 10000 );
				camera.position.z = 1000;

				scene = new THREE.Scene();

				//

				const numParticles = AMOUNTX * AMOUNTY;

				const positions = new Float32Array( numParticles * 3 );
				const scales = new Float32Array( numParticles );

				let i = 0, j = 0;

				for ( let ix = 0; ix < AMOUNTX; ix ++ ) {

					for ( let iy = 0; iy < AMOUNTY; iy ++ ) {

						positions[ i ] = ix * SEPARATION - ( ( AMOUNTX * SEPARATION ) / 2 ); // x
						positions[ i + 1 ] = 0; // y
						positions[ i + 2 ] = iy * SEPARATION - ( ( AMOUNTY * SEPARATION ) / 2 ); // z

						scales[ j ] = 1;

						i += 3;
						j ++;

					}

				}

				const geometry = new THREE.BufferGeometry();
				geometry.setAttribute( 'position', new THREE.BufferAttribute( positions, 3 ) );
				geometry.setAttribute( 'scale', new THREE.BufferAttribute( scales, 1 ) );

				const material = new THREE.ShaderMaterial( {

					uniforms: {
						color: { value: new THREE.Color( 0xffffff ) },
					},
					vertexShader: document.getElementById( 'vertexshader' ).textContent,
					fragmentShader: document.getElementById( 'fragmentshader' ).textContent

				} );

				//

				particles = new THREE.Points( geometry, material );
				scene.add( particles );

				//

				renderer = new THREE.WebGLRenderer( { antialias: true } );
				renderer.setPixelRatio( window.devicePixelRatio );
                renderer.setSize(window.innerWidth, animatedHeaderHeight );
				renderer.setAnimationLoop( animate );
				container.appendChild( renderer.domElement );

				container.style.touchAction = 'none';
				container.addEventListener( 'pointermove', onPointerMove );

				//

                window.addEventListener( 'resize', onWindowResize );

			}

			function onWindowResize() {

				windowHalfX = window.innerWidth / 2;

				camera.aspect = window.innerWidth / animatedHeaderHeight; 
				camera.updateProjectionMatrix();

				renderer.setSize(window.innerWidth, animatedHeaderHeight);

			}

			//

			function onPointerMove( event ) {

				if ( event.isPrimary === false ) return;

				mouseX = event.clientX - windowHalfX;
				mouseY = event.clientY - windowHalfY;

			}

			//

			function animate() {
				render();

			}

			function render() {

				camera.position.x += ( mouseX - camera.position.x ) * .05;
				camera.position.y += ( - mouseY - camera.position.y ) * .05;
				camera.lookAt( scene.position );

				const positions = particles.geometry.attributes.position.array;
				const scales = particles.geometry.attributes.scale.array;

				let i = 0, j = 0;

				for ( let ix = 0; ix < AMOUNTX; ix ++ ) {

					for ( let iy = 0; iy < AMOUNTY; iy ++ ) {

						positions[ i + 1 ] = ( Math.sin( ( ix + count ) * 0.3 ) * 50 ) +
										( Math.sin( ( iy + count ) * 0.5 ) * 50 );

						scales[ j ] = ( Math.sin( ( ix + count ) * 0.3 ) + 1 ) * 20 +
										( Math.sin( ( iy + count ) * 0.5 ) + 1 ) * 20;

						i += 3;
						j ++;

					}

				}

				particles.geometry.attributes.position.needsUpdate = true;
				particles.geometry.attributes.scale.needsUpdate = true;

				renderer.render( scene, camera );

				count += 0.1;

			}

        </script>

    </div>
  <div class="wrapper"><a class="site-title" rel="author" href="/">Harlinn</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Cpp/Cpp.html">C++</a><a class="page-link" href="/Databases/Databases.html">Databases</a><a class="page-link" href="/DotNet/DotNet.html">.Net</a><a class="page-link" href="/Java/Java.html">Java</a><a class="page-link" href="/Julia/Julia.html">Julia</a><a class="page-link" href="/Python/Python.html">Python</a><a class="page-link" href="/R/R.html">R</a><a class="page-link" href="/Rust/Rust.html">Rust</a><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Single Instruction Multiple Data (SIMD)</h1>
  </header>

  <div class="post-content">
    <p>Single Instruction Multiple Data (SIMD) is a parallel computing technology 
where a single instruction operates on multiple values at 
the same time. SIMD is used to implement artificial intelligence (AI), 
machine learning (ML), high performance graphics, and other data science solutions. 
SIMD enables efficient data processing and increased computational performance.</p>

<p>The <a href="/Cpp/Harlinn.Windows/Harlinn.Common.Core/Harlinn.Common.Core.html">Harlinn.Common.Core</a> 
library allows developers to create highly optimized SIMD code, without 
the complexity usually associated with using the SIMD intrinsic operations:</p>

<pre><code class="language-C++">using Vector = Math::Vector&lt;float, 4&gt;;

Vector v1( 1.0f, 2.0f, 3.f, 1.0f );
Vector v2( 5.0f, 3.0f, 3.f, 2.0f );
Vector v3 = (v2 + Dot(v1,v2)) / Sin(v1);

</code></pre>
<p>The above example uses the <a href="FastLinearAlgebra.html">Fast Linear Algebra Classes for Games and Graphics</a>, which 
leverages the <code class="language-plaintext highlighter-rouge">Traits&lt;T,N&gt;</code> specializations discussed below.</p>

<p><code class="language-plaintext highlighter-rouge">HCCSIMD.h</code> is header only, and does not require linking with <code class="language-plaintext highlighter-rouge">Harlinn.Common.Core.lib</code>.</p>

<h1 id="single-instruction-multiple-data">Single Instruction Multiple Data</h1>

<p>The interface to SIMD operations in <a href="/Cpp/Harlinn.Windows/Harlinn.Common.Core/Harlinn.Common.Core.html">Harlinn.Common.Core</a> 
is provided in <code class="language-plaintext highlighter-rouge">HCCSIMD.h</code> contained within the <code class="language-plaintext highlighter-rouge">Harlinn::Common::Core::SIMD</code> namespace through a set of specializations
of the template:</p>

<pre><code class="language-C++">template&lt;typename T, size_t N&gt;
struct Traits : public std::false_type
{ };
</code></pre>

<p>The motivation for creating the <code class="language-plaintext highlighter-rouge">Traits&lt;T,N&gt;</code> specializations is that they can be used to implement C++ templates
providing a common implementation that can be used with multiple data types. Like the multiplication for
quaternions:</p>

<pre><code class="language-C++">template&lt;typename T&gt;
    requires IsFloatingPoint&lt;T&gt;
QuaternionSimd&lt;T&gt; QuaternionMultiply(const QuaternionSimd&lt;T&gt;&amp; q1, 
                                    const QuaternionSimd&lt;T&gt;&amp; q2 )
{
    using QuaternionSimd = QuaternionSimd&lt;T&gt;;
    using Traits = typename QuaternionSimd::Traits;
    using FloatT = typename Traits::Type;
    using Constants = Constants&lt;FloatT&gt;;
    constexpr Traits::SIMDType controlWZYX = 
        { { Constants::One, Constants::MinusOne, 
            Constants::One, Constants::MinusOne } };
    constexpr Traits::SIMDType controlZWXY = 
        { { Constants::One, Constants::One, 
            Constants::MinusOne, Constants::MinusOne } };
    constexpr Traits::SIMDType controlYXWZ = 
        { { Constants::MinusOne, Constants::One, 
            Constants::One, Constants::MinusOne } };
            
    auto q2X = Traits::At&lt;0&gt;( q2.simd );
    auto q2Y = Traits::At&lt;1&gt;( q2.simd );
    auto q2Z = Traits::At&lt;2&gt;( q2.simd );
    auto result = Traits::At&lt;3&gt;( q2.simd );
            
    result = Traits::Mul( result, q1.simd );
    auto q1Swizzle = Traits::Swizzle&lt;0, 1, 2, 3&gt;( q1.simd );
            
    q2X = Traits::Mul( q2X, q1Swizzle );
    q1Swizzle = Traits::Swizzle&lt;2, 3, 0, 1&gt;( q1Swizzle );
            
    result = Traits::FMAdd( q2X, controlWZYX, result );
            
    q2Y = Traits::Mul( q2Y, q1Swizzle );
    q1Swizzle = Traits::Swizzle&lt;0, 1, 2, 3&gt;( q1Swizzle );
            
    q2Y = Traits::Mul( q2Y, controlZWXY );
    q2Z = Traits::Mul( q2Z, q1Swizzle );
            
    q2Y = Traits::FMAdd( q2Z, controlYXWZ, q2Y );
    result = Traits::Add( result, q2Y );
    return result;
}
</code></pre>

<p>The <code class="language-plaintext highlighter-rouge">Traits&lt;T,N&gt;</code> specializations provides access to the SIMD intrinsic functions, 
and strives to maintain a uniform set of names for the implemented functions. The
second template argument is sometimes used to select function implementations
optimized for <code class="language-plaintext highlighter-rouge">N</code> elements in the SIMD type.</p>

<p><code class="language-plaintext highlighter-rouge">T</code> is the type of the values to use in the computations, and <code class="language-plaintext highlighter-rouge">N</code> is 
the required number of valid elements in the SIMD type. The SIMD type is a representation 
of a CPU register used for SIMD operations. The Intel/AMD x64 architecture
provides several SIMD types:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">__m128</code> types: These types are used with the Streaming SIMD Extensions and Streaming SIMD Extensions 2 instructions intrinsics, and maps to the XMM[0-7] registers.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">__m128</code>: Holds four 32-bit floating point values.</li>
      <li><code class="language-plaintext highlighter-rouge">__m128i</code>: Holds sixteen 8-bit, eight 16-bit, four 32-bit, or two 64-bit integer values.</li>
      <li><code class="language-plaintext highlighter-rouge">__m128d</code>: Holds two 64-bit floating point values.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">__m256</code> types: These types are used with the AVX/AVX2 extensions, and maps to the YMM[0-15] registers.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">__m256</code>: Holds eight 32-bit floating point values.</li>
      <li><code class="language-plaintext highlighter-rouge">__m256i</code>: Holds thirty-two 8-bit, sixteen 16-bit, eight 32-bit, or four 64-bit integer values.</li>
      <li><code class="language-plaintext highlighter-rouge">__m256d</code>: Holds four 64-bit double precision floating point values.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">__m512</code> types: These types are used with the AVX 512 extensions, and maps to the ZMM[0-31] registers.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">__m512</code>: Holds sixteen 32-bit floating point values.</li>
      <li><code class="language-plaintext highlighter-rouge">__m512i</code>: Holds sixty-four 8-bit, thirty-two 16-bit, sixteen 32-bit, or eight 64-bit integer values.</li>
      <li><code class="language-plaintext highlighter-rouge">__m512d</code>: Holds eight 64-bit double precision floating point values.</li>
    </ul>
  </li>
</ul>

<p>The above data types are not basic C/C++ data types, and have several usage restrictions:</p>

<ul>
  <li>Can only be used on either side of an assignment, as a return value, or as a parameter. Cannot be used in regular arithmetic expressions <code class="language-plaintext highlighter-rouge">+</code>, <code class="language-plaintext highlighter-rouge">-</code>, <code class="language-plaintext highlighter-rouge">*</code>, <code class="language-plaintext highlighter-rouge">/</code>, etc.</li>
  <li>Can be used as objects in aggregates, such as unions, to access the byte elements and structures.</li>
  <li>Can only be operated on using the intrinsic functions implemented by the compiler.</li>
</ul>

<p>Before doing any operations on SIMD type variables, they must be loaded using special intrinsic functions:</p>

<pre><code class="language-C++">_mm256_load_ps( ptrToFloats );
</code></pre>
<p>Where, in this case, <code class="language-plaintext highlighter-rouge">ptrToFloats</code> is a 32 byte aligned pointer to 8 single precision floating point values.</p>

<h3 id="the-intel-intrinsics-guide">The Intel Intrinsics Guide</h3>

<p>The <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">Intel Intrinsics Guide</a> contains 
a brief description of the available intrinsic functions. Itâ€™s a bit short on details, but when needed - the relevant
details can be found in the <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">Intel 64 and IA-32 Architectures Software Developer Manuals</a>.</p>

<h3 id="simdtraitstn">SIMD::Traits&lt;T,N&gt;</h3>

<p>All the intrinsic functions have unique, C style names, making it awkward to use them directly inside 
templates. The intrinsic for adding two <code class="language-plaintext highlighter-rouge">__m128</code> variables is called <code class="language-plaintext highlighter-rouge">_mm_add_ps</code>:</p>

<pre><code class="language-C++">auto v3 = _mm_add_ps(v1,v2);
</code></pre>
<p><code class="language-plaintext highlighter-rouge">_mm_add_ps</code> operates on single precision floating point values, adding the four values held by
<code class="language-plaintext highlighter-rouge">v1</code> to the corresponding four values held by <code class="language-plaintext highlighter-rouge">v2</code> and storing the result in <code class="language-plaintext highlighter-rouge">v3</code>.</p>

<p>The intrinsic for adding two <code class="language-plaintext highlighter-rouge">__m128d</code> variables is called <code class="language-plaintext highlighter-rouge">_mm_add_pd</code>:</p>
<pre><code class="language-C++">auto v3 = _mm_add_pd(v1,v2);
</code></pre>
<p><code class="language-plaintext highlighter-rouge">_mm_add_pd</code> does the same job as <code class="language-plaintext highlighter-rouge">_mm_add_ps</code>, but operates on double precision floating point values, 
and only two of those fits inside a <code class="language-plaintext highlighter-rouge">__m128d</code> variable.</p>

<p>The intrinsic that actually performs the same operation as <code class="language-plaintext highlighter-rouge">_mm_add_ps</code> for 
double precision floating point values is called <code class="language-plaintext highlighter-rouge">_mm256_add_pd</code>:</p>

<pre><code class="language-C++">auto v3 = _mm256_add_pd(v1,v2);
</code></pre>

<p><code class="language-plaintext highlighter-rouge">_mm256_add_pd</code> works with two <code class="language-plaintext highlighter-rouge">__m256d</code> variables, and they hold four double 
precision floating point values.</p>

<p>The <code class="language-plaintext highlighter-rouge">Traits&lt;T,N&gt;</code> specializations are a practical solution, wrapping the various 
intrinsic functions, making them accessible using the same name:</p>

<pre><code class="language-C++">using Traits = Traits&lt;float,4&gt;;
auto v3 = Traits::Add(v1,v2);
</code></pre>

<p><code class="language-plaintext highlighter-rouge">Traits&lt;float,4&gt;</code> and <code class="language-plaintext highlighter-rouge">Traits&lt;double,4&gt;</code> holds the same number of elements.</p>

<pre><code class="language-C++">using Traits = Traits&lt;double,4&gt;;
auto v3 = Traits::Add(v1,v2);
</code></pre>

<p>This can be used to implement a template that adds the corresponding elements of two vectors:</p>

<pre><code class="language-C++">template&lt;typename ValueT&gt;
    requires std::is_same_v&lt;ValueT,char&gt; || std::is_same_v&lt;ValueT, Byte&gt; || 
                std::is_same_v&lt;ValueT, SByte&gt; || std::is_same_v&lt;ValueT, Int16&gt; || 
                std::is_same_v&lt;ValueT, UInt16&gt; || std::is_same_v&lt;ValueT, Int32&gt; || 
                std::is_same_v&lt;ValueT, UInt32&gt; || std::is_same_v&lt;ValueT, Int64&gt; || 
                std::is_same_v&lt;ValueT, UInt64&gt; || std::is_same_v&lt;ValueT, float&gt; || 
                std::is_same_v&lt;ValueT, double&gt;
std::vector&lt;ValueT&gt; Add( const std::vector&lt;ValueT&gt;&amp; v1, 
                    const std::vector&lt;ValueT&gt;&amp; v2 )
{
    using Limits = SIMD::TraitLimits&lt;ValueT&gt;;
    using Traits = SIMD::Traits&lt;ValueT, Limits::Size&gt;;

    size_t resultSize = std::max( v1.size( ), v2.size( ) );
    size_t operationCount = std::min( v1.size( ), v2.size( ) );
    size_t iterationCount = operationCount / Limits::Size;
    size_t remainingCount = operationCount % Limits::Size;

    std::vector result;
    result.resize( resultSize );

    const auto* p1 = v1.data( );
    const auto* p2 = v2.data( );
    auto* pR = result.data( );
    for ( size_t i = 0; i &lt; iterationCount; ++i )
    {
        Traits::Store( pR, Traits::Add( Traits::Load( p1 ), Traits::Load( p2 ) ) );
        p1 += Limits::Size;
        p2 += Limits::Size;
        pR += Limits::Size;
    }
    for ( size_t i = 0; i &lt; remainingCount; ++i )
    {
        *pR = *p1 + *p2;
        p1++;
        p2++;
        pR++;
    }
    if ( v1.size( ) &gt; v2.size( ) )
    {
        std::copy( p1, p1 + ( resultSize - operationCount ), pR );
    }
    else if ( v1.size( ) &lt; v2.size( ) )
    {
        std::copy( p2, p2 + ( resultSize - operationCount ), pR );
    }
    return result;
}

</code></pre>

<p>The above example works for any of the supported data types, and uses <code class="language-plaintext highlighter-rouge">SIMD::TraitLimits&lt;ValueT&gt;::Size</code>
to get the optimal value of <code class="language-plaintext highlighter-rouge">N</code> for the type <code class="language-plaintext highlighter-rouge">ValueT</code>.</p>

<p>The number of available intrinsic functions can be a bit overwhelming, and the <code class="language-plaintext highlighter-rouge">Traits&lt;T,N&gt;</code> specializations
groups the intrinsic functions according to the type they are designed to work with. The various
<code class="language-plaintext highlighter-rouge">Traits&lt;T,N&gt;</code> specializations do not support the same set of functions, but do share a common subset
of operations.</p>

<p><code class="language-plaintext highlighter-rouge">Traits&lt;float,4&gt;::Swizzle&lt;0,1,2,3&gt;( v )</code> and <code class="language-plaintext highlighter-rouge">Traits&lt;double,4&gt;::Swizzle&lt;0,1,2,3&gt;( v )</code> will 
both reverse the order of the <code class="language-plaintext highlighter-rouge">4</code> elements in <code class="language-plaintext highlighter-rouge">v</code>, and the first will invoke <code class="language-plaintext highlighter-rouge">_mm_permute_ps</code> while
the second invokes <code class="language-plaintext highlighter-rouge">_mm256_permute4x64_pd</code>, not <code class="language-plaintext highlighter-rouge">_mm256_permute_pd</code> which can only swap values inside a 128 bit lane,
and not <code class="language-plaintext highlighter-rouge">_mm_permute_pd</code> which operates on the <code class="language-plaintext highlighter-rouge">__m128d</code> SIMD type and can only hold two double precision values.</p>

<p>The template arguments mimics the <code class="language-plaintext highlighter-rouge">_MM_SHUFFLE</code> macro, where the first argument selects the value
that goes into the highest position in the resulting SIMD type, the second argument selects the value
that goes into the second highest positions, the third selects the value that goes into the second lowest 
position, and the fourth selects the value that goes into the lowest position. <code class="language-plaintext highlighter-rouge">0</code> selects the value
from the lowest position in <code class="language-plaintext highlighter-rouge">v</code>, while <code class="language-plaintext highlighter-rouge">3</code> selects the value from the highest position in <code class="language-plaintext highlighter-rouge">v</code>.</p>

<p>There are more than <code class="language-plaintext highlighter-rouge">80</code> intrinsic functions with <em>permute</em> in their name, and just separating them
by the type they operate on makes SIMD development more manageable.</p>

<p>The C/C++ compiler handles register allocation and instruction scheduling, but using the SIMD extensions can be complex:</p>

<pre><code class="language-C++">auto rmm1 = _mm_shuffle_ps( a, a, _MM_SHUFFLE( 3, 0, 2, 1 ) );
auto rmm2 = _mm_shuffle_ps( b, b, _MM_SHUFFLE( 3, 1, 0, 2 ) );
auto rmm3 = _mm_mul_ps( rmm1, b );
auto rmm4 = _mm_mul_ps( rmm1, rmm2 );
auto rmm5 = _mm_shuffle_ps( rmm3, rmm3, _MM_SHUFFLE( 3, 0, 2, 1 ) );
return _mm_sub_ps( rmm4, rmm5 );
</code></pre>

<p>The above computes the cross product between two vectors, <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>, each containing 
three 32-bit floating point values.</p>

<p>Using the <code class="language-plaintext highlighter-rouge">SIMD::Traits&lt;float,3&gt;</code>, reduces the above to:</p>

<pre><code class="language-C++">return SIMD::Traits&lt;float,3&gt;::Cross( a, b );
</code></pre>

<p>While:</p>

<pre><code class="language-C++">return SIMD::Traits&lt;float,2&gt;::Cross( a, b );
</code></pre>

<p>calculates the cross product for vectors with only two elements, expanding to:</p>

<pre><code class="language-C++">auto rmm1 = _mm_permute_ps( b, _MM_SHUFFLE( 0, 1, 0, 1 ) );
rmm1 = _mm_mul_ps( rmm1, a );
auto rmm2 = _mm_permute_ps( rmm1, _MM_SHUFFLE( 1, 1, 1, 1 ) );
rmm1 = _mm_sub_ss( rmm1, rmm2 );
return _mm_permute_ps( rmm1, _MM_SHUFFLE( 0, 0, 0, 0 ) );
</code></pre>

<p>Both operates on a <code class="language-plaintext highlighter-rouge">__m128</code> holding four 32-bit floating point values, but 
last one calculates the cross product using only the values contained within the two
lowest order positions of the <code class="language-plaintext highlighter-rouge">__m128</code>.</p>


  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Harlinn</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Harlinn</li><li><a class="u-email" href="mailto:espen@harlinn.no">espen@harlinn.no</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/Harlinn"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">Harlinn</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is my personal site. </p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
